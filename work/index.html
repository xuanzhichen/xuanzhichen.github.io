<!DOCTYPE html>
<html
  lang="en"
  dir="ltr"
  
><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">


<title>Work | Homepage</title>

<meta name="generator" content="Hugo Eureka 0.9.3" />
<link rel="stylesheet" href="https://xuanzhichen.github.io/css/eureka.min.9cec6350e37e534b0338fa9a085bf06855de3b0f2dcf857e792e5e97b07ea905d4d5513db554cbc26a9c3da622bae92d.css">
<script defer src="https://xuanzhichen.github.io/js/eureka.min.fa9a6bf6d7a50bb635b4cca7d2ba5cf3dfb095ae3798773f1328f7950028b48c17d06276594e1b5f244a25a6c969a705.js"></script>













<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
  href="https://fonts.googleapis.com/css2?family=Lora:wght@400;600;700&amp;family=Noto&#43;Serif&#43;SC:wght@400;600;700&amp;display=swap"
  as="style" onload="this.onload=null;this.rel='stylesheet'">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/styles/base16/solarized-light.min.css"
   media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/highlight.min.js"
   crossorigin></script>
  <script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/languages/dart.min.js"
     crossorigin></script>
<link rel="stylesheet" href="https://xuanzhichen.github.io/css/highlightjs.min.2958991528e43eb6fc9b8c4f2b8e052f79c4010718e1d1e888a777620e9ee63021c2c57ec7417a3108019bb8c41943e6.css" media="print" onload="this.media='all';this.onload=null">


<script defer type="text/javascript" src="https://xuanzhichen.github.io/js/fontawesome.min.95304b4ae74be494ff20fcc4a2da53d579715352f453ee025f7b41e1ab63b5b52a82c7e2403d9e3742b73d2fbd69b5be.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"
   integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ"  media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" 
  integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY"  crossorigin></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
   integrity="sha384-&#43;XBljXPPiv&#43;OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"  crossorigin></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
        { left: "\\(", right: "\\)", display: false },
        { left: "\\[", right: "\\]", display: true }
      ],
    });
  });
</script>


<script defer src="https://cdn.jsdelivr.net/npm/mermaid@8.14.0/dist/mermaid.min.js" 
  integrity="sha384-atOyb0FxAgN9LyAc6PEf9BjgwLISyansgdH8/VXQH8p2o5vfrRgmGIJ2Sg22L0A0"  crossorigin></script>
<link rel="preconnect" href="https://www.google-analytics.com" crossorigin>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123-45"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());
  gtag('config', 'UA-123-45');
</script>



<meta name="description"
  content="My academic interest in particular rests in machine intelligence, computational data analysis, and information technology. In the future, I may also be interested in addressing commercial and financial problems in industries by drawing inspiration from computer science and applied mathematics.
Remainder: Part of work is also tied to my papers referring to the &ldquo;Academic Papers&rdquo; on this page.
Popularization of Causal Science (2023-2024) Intro: A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
      "@type": "ListItem",
      "position": 1 ,
      "name":"Homepage",
      "item":"https://xuanzhichen.github.io/"},{
      "@type": "ListItem",
      "position": 2 ,
      "name":"Work",
      "item":"https://xuanzhichen.github.io/work/"}]
}
</script>



<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://xuanzhichen.github.io/work/"
    },
    "headline": "Work | Homepage","wordCount":  566 ,
    "publisher": {
        "@type": "Person",
        "name": "Homepage",
        },
    "description": "My academic interest in particular rests in machine intelligence, computational data analysis, and information technology. In the future, I may also be interested in addressing commercial and financial problems in industries by drawing inspiration from computer science and applied mathematics.\nRemainder: Part of work is also tied to my papers referring to the \u0026ldquo;Academic Papers\u0026rdquo; on this page.\nPopularization of Causal Science (2023-2024) Intro: A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective"
}
</script><meta property="og:title" content="Work | Homepage" />
<meta property="og:type" content="article" />



<meta property="og:url" content="https://xuanzhichen.github.io/work/" />




<meta property="og:description" content="My academic interest in particular rests in machine intelligence, computational data analysis, and information technology. In the future, I may also be interested in addressing commercial and financial problems in industries by drawing inspiration from computer science and applied mathematics.
Remainder: Part of work is also tied to my papers referring to the &ldquo;Academic Papers&rdquo; on this page.
Popularization of Causal Science (2023-2024) Intro: A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective" />




<meta property="og:locale" content="en" />



<meta property="og:locale:alternate" content="zh" />




<meta property="og:site_name" content="Homepage" />









<meta property="article:section" content="" />





  
  <body class="bg-secondary-bg flex min-h-screen flex-col">
    <header
      class="min-h-16 pl-scrollbar bg-secondary-bg fixed z-50 flex w-full items-center shadow-sm"
    >
      <div class="mx-auto w-full max-w-screen-xl"><script>
    let storageColorScheme = localStorage.getItem("lightDarkMode")
    if (((storageColorScheme == 'Auto' || storageColorScheme == null) && window.matchMedia("(prefers-color-scheme: dark)").matches) || storageColorScheme == "Dark") {
        document.getElementsByTagName('html')[0].classList.add('dark')
    }
</script>
<nav class="flex items-center justify-between flex-wrap px-4 py-4 md:py-0">
    <a href="/" class="me-6 text-primary-text text-xl font-bold">Homepage</a>
    <button id="navbar-btn" class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
        <i class="fas fa-bars"></i>
    </button>

    <div id="target"
        class="hidden block md:flex md:grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20">
        <div class="md:flex md:h-16 text-sm md:grow pb-4 md:pb-0 border-b md:border-b-0">
            <a href="/cv/cv_241031.pdf" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">CV</a>
            <a href="/experience/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">Experiences</a>
            <a href="/work/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  selected-menu-item  me-4">Work</a>
            <a href="/acknowledgements/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">Acknowledgements</a>
            <a href="/blogs/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">Blogs</a>
        </div>

        <div class="flex">
            <div class="relative pt-4 md:pt-0">
                <div class="cursor-pointer hover:text-eureka" id="lightDarkMode">
                    <i class="fas fa-adjust"></i>
                </div>
                <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id="is-open">
                </div>
                <div class="absolute flex flex-col start-0 md:start-auto end-auto md:end-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40"
                    id='lightDarkOptions'>
                    <span class="px-4 py-1 hover:text-eureka" name="Light">Light</span>
                    <span class="px-4 py-1 hover:text-eureka" name="Dark">Dark</span>
                    <span class="px-4 py-1 hover:text-eureka" name="Auto">Auto</span>
                </div>
            </div>
            <div class="relative pt-4 ps-4 md:pt-0">
                <div class="cursor-pointer hover:text-eureka" id="languageMode">
                    <i class="fas fa-globe"></i>
                    <span class="ps-1">English</span>
                </div>
                <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id="is-open-lang">
                </div>
                <div class="absolute flex flex-col start-0 md:start-auto end-auto md:end-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40"
                    id='languageOptions'>
                    <a class="px-4 py-1 hover:text-eureka" href="https://xuanzhichen.github.io/work/">English</a>
                    <a class="px-4 py-1 hover:text-eureka" href="https://xuanzhichen.github.io/zh/work/">简体中文</a>
                </div>
            </div>
        </div>
    </div>

    <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id="is-open-mobile">
    </div>

</nav>
<script>
    
    let element = document.getElementById('lightDarkMode')
    if (storageColorScheme == null || storageColorScheme == 'Auto') {
        document.addEventListener('DOMContentLoaded', () => {
            window.matchMedia("(prefers-color-scheme: dark)").addEventListener('change', switchDarkMode)
        })
    } else if (storageColorScheme == "Light") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'sun')
        element.firstElementChild.classList.add('fa-sun')
    } else if (storageColorScheme == "Dark") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'moon')
        element.firstElementChild.classList.add('fa-moon')
    }

    document.addEventListener('DOMContentLoaded', () => {
        getcolorscheme();
        switchBurger();
        switchLanguage()
    });
</script>
</div>
    </header>
    <main class="grow pt-16">
        <div class="pl-sc rollbar">
          <div class="mx-auto w-full max-w-screen-xl lg:px-4 xl:px-8">
  
  

  
  <div class="grid grid-cols-2 gap-4 lg:grid-cols-8 lg:pt-16">
    <div
      class=" bg-secondary-bg col-span-2 rounded px-6 py-8 lg:col-span-6"
    >
      <article class="prose">
  <h1 class="mb-4">Work</h1>

  

  
  

  <p>My academic interest in particular rests in machine intelligence, computational data analysis, and information technology. In the future, I may also be interested in addressing commercial and financial problems in industries by drawing inspiration from computer science and applied mathematics.</p>
<p><font color=#38B2AC>Remainder</font>: Part of work is also tied to my papers referring to the &ldquo;Academic Papers&rdquo; on this page.</p>
<!-- ## Sample Slides of My Undergrad Work 
**Intro**: [Put your pdf converted from the PPT collection]()

The following pieces involve testing contents and please ignore.Video provides a powerful way to help you prove your point. When you click Online Video, you can paste in the embed code. The following pieces involve testing contents and please ignore. -->
<h2 id="popularization-of-causal-science-2023-2024">Popularization of Causal Science (2023-2024)</h2>
<p><strong>Intro</strong>: <strong><a href="https://www.youtube.com/playlist?list=PLSyPZ5M_YtDQA6YQ7VNGVoNlYZYo_xgpu">A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective</a></strong></p>
<!-- - Notions of <font color=#38B2AC>counterfactuals</font> and <font color=#38B2AC>intervention</font>, the paradigm of human causal thinking, are introduced into two (simplified) applications
of causal relation analysis in significant issues such as <font color=#38B2AC>climate
change</font> and <font color=#38B2AC>COVID-19</font>.

- Introduce the <font color=#38B2AC>"down-stream" capability</font> of a given causal diagram, and retrospectively the <font color=#38B2AC>"upstream" task</font>
focusing on how to learn the causal diagram—namely the "Causal Discovery". -->
<p>Since I was motivated by fundamental ideas of causality from a popular science book named &lsquo;<a href="https://en.wikipedia.org/wiki/The_Book_of_Why">The Book of WHY</a>&rsquo; (by Turing Award winner Judea Pearl), I attempt to further create connections in the book to <font color=#38B2AC>other celebrated books by giant leaders in causation</font>, centering around subjects of &ldquo;<font color=#38B2AC>causal diagram learning</font>&rdquo;.</p>
<!-- Though ideas of causal diagram learning introduced in this paper are the tip of the iceberg,  -->
<p>I want to show that ideas of Causal Discovery are deeply rooted in the past by <font color=#38B2AC>standing on the shoulders of these giants</font>. (e.g. <a href="https://direct.mit.edu/books/book/2057/Causation-Prediction-and-Search">Causation, Prediction, and Search</a> [2001] (Peter Spirtes, Clark Glymour); <a href="http://bayes.cs.ucla.edu/jp_home.html">Causality</a> [2008] (Judea Pearl);
<a href="https://people.math.ethz.ch/~jopeters/elements.html">Elements of Causal Inference</a> [2017] (Jonas Peters, Bernhard Schölkopf, etc))</p>
<!-- However, I wish that points of view from the work of the giants in causal science <font color=#38B2AC>might be beneficial to future progression of AI, cognitive neuroscience, and other related fields</font>. -->
<!-- - Relevant paper (on this page): "A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective, 2024." -->
<!-- three of celebrated books herein include: Causation, Prediction, and Search [2001] (Peter Spirtes, Clark Glymour); Causality [2008] (Judea Pearl); Elements of Causal Inference [2017] (Jonas Peters, Bernhard Schölkopf, etc).  -->
<!-- - Also see the article "*A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective*" in `Papers.2024` on this page. -->
<h2 id="causality-algorithms-programming-2022-2023">Causality Algorithms Programming (2022-2023)</h2>
<p><strong>Intro</strong>: <strong><a href="https://xuanzhichen.github.io/cadimulc/">Cadimulc: Light Python Package for Hybrid-Based Causal Discovery</a></strong></p>
<p><font color=#38B2AC>CADIMULC</font> is a <a href="https://github.com/xuanzhichen/cadimulc">open-source github repo</a> standing for <font color=#38B2AC>CA</font>usal <font color=#38B2AC>DI</font>scovery with <font color=#38B2AC>M</font>ultiple <font color=#38B2AC>L</font>atent <font color=#38B2AC>C</font>onfounders, which provides easy-to-use APIs to learn an empirical causal graph from raw data with relatively efficiency.</p>
<p>For example, It integrates the <font color=#38B2AC>implementations of hybrid-based causality approaches</font> such as the <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=Causal+discovery+in+linear+non-gaussian+acyclic+model+with+multiple+latent+confounders&amp;btnG=">MLC-LiNGAM algorithm</a>,
along with the &ldquo;micro&rdquo; <font color=#38B2AC>workflow of causal discovery (Causal Inference)</font>, such as data generation, learning results evaluation, and graphs visualization.</p>
<h2 id="research-in-causal-science-2-2023">Research in Causal Science (2) (2023)</h2>
<p><strong>Intro</strong>: <strong><a href="slides/a_survey_on_causal_discovery_with_incomplete_time-series_data.pdf">A Survey on Causal Discovery with Incomplete Time-Series Data</a></strong></p>
<p>With the rapid growth of massive <font color=#38B2AC>time-series</font> data, inferring temporal-based causal relationships from data — <font color=#38B2AC>Temporal Causal Discovery</font> (TCD) — has become an important and challenging task in recent years, holding both scientific significance and commercial value for uncovering data generative mechanism.</p>
<p>Distinguishing from existing reviews, we focus on the latest research progress in the task of <font color=#38B2AC>TCD with incomplete data</font>, summarizing the <font color=#38B2AC>philosophies and paradigms</font> reflected in current research methods.</p>
<h2 id="research-in-causal-science-1-2022-2023">Research in Causal Science (1) (2022-2023)</h2>
<p><strong>Intro</strong>: <strong><a href="https://www.youtube.com/watch?v=4bpx1DPd_Vg&amp;list=PLSyPZ5M_YtDRr9z25YgUjqs7-RLr-x5yg&amp;index=2">Non-linear Causal Discovery for Additive Noise Model with Multiple Latent Confounders</a></strong></p>
<!-- Could we teach AI to manoeuvre causation via the specific identification entailed by data, in particular underneath the data in a <font color=#38B2AC>complicate learning environment</font>? An environment in which
"generic data relations" are prone to be <font color=#38B2AC>non-linear</font>, and even impacts from the <font color=#38B2AC>multiple
unknown factors</font> are persisting. 

[Existing solutions](https://proceedings.mlr.press/v161/maeda21a.html) towards the issue might be either theoretically elusive in <font color=#38B2AC>formal representation</font> or notoriously difficult in <font color=#38B2AC>algorithmic computation</font>. Such motivations have driven us to design a <font color=#38B2AC>theory-guided</font> and <font color=#38B2AC>practically effective</font> causal discovery algorithm. -->
<p>How should we appreciate “causal structures” underneath the data from a complicate learning environment? An environment in which “<font color=#38B2AC>generic data relations</font>” are prone to be <font color=#38B2AC>non-linear</font>, and even impacts from the <font color=#38B2AC>multiple unknown factors</font> are persisting</p>
<p><a href="https://proceedings.mlr.press/v161/maeda21a.html">Existing solutions</a> towards generic causal discovery might be either theoretically elusive in <font color=#38B2AC>formal representation</font> or notoriously difficult in <font color=#38B2AC>algorithmic computation</font>. Such motivations have driven us to design a <font color=#38B2AC>theory-guided</font> and <font color=#38B2AC>practically effective</font> <a href="https://github.com/xuanzhichen/cadimulc/blob/master/cadimulc/hybrid_algorithms/hybrid_algorithms.py">causal discovery algorithm</a>.</p>
<!-- - Relevant paper (on this page): "Non-linear Causal Discovery for Additive Noise Model with Multiple Latent Confounders, 2023." -->
<!-- - Causal discovery, namely to recover <font color=#38B2AC>data generation</font> mechanism represented (vaguely) by <font color=#38B2AC>causal graphs</font>,
is an emerging scientific discipline to spot causal significance from the merely observed and static data.

- Practically, only <font color=#38B2AC>a subset of</font> variables relative to the reasonable dataset has been measured, leading to
<font color=#38B2AC>potential confounding</font> from these latent variables; meanwhile, <font color=#38B2AC>causality constraints</font> that have paid off
in linear cases are now impeded, due to the <font color=#38B2AC>general non-linear</font> interaction between variables. -->
<h2 id="academic-papers">Academic Papers</h2>
<!-- ### Working
- **<font color=#38B2AC>*Chen, XZ.*</font>** A Brief Discussion on Causal Inference for Time-Series Data -->
<h3 id="publishments">Publishments</h3>
<!-- ### 2022 -->
<!-- - *Liu, YQ.\*, Zhu, WH.\*, Qiao, J.\*, Huang, ZY., Xiang, Yu.,* **<font color=#38B2AC>*Chen, XZ.*</font>**, *Chen, W., Cai, RC.* **[Causal Alignment Based Fault Root Causes Localization for Wireless Network](https://ieeexplore.ieee.org/abstract/document/9746064)**.
*<font color=#FF5733>ICASSP; IEEE International Conference on Acoustics, Speech and Signal Processing.</font>* -->
<ul>
<li>Liu, Y.*, Zhu, W.*, Qiao, J.*, Huang, Z., Xiang, Y., <strong><font color=#38B2AC>Chen, X.</font></strong>, Chen, W. and Cai, R., <strong>2022</strong>. <a href="https://ieeexplore.ieee.org/abstract/document/9746064">Causal Alignment Based Fault Root Causes Localization for Wireless Network</a>. <font color=#FF5733>In <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.</font>
  <!-- > Though supervised methods have shown promising results, most of the existing approaches assume that
  the training and the testing samples are independent and
  identical distributed. Such an assumption usually does
  not hold due to network faults that may occur across different domains (distribution shift). Thus, it is necessary to align distributions between
  the training and test data set.  -->
</li>
</ul>
<h3 id="preprints">Preprints</h3>
<!-- ### 2024 -->
<ul>
<li><strong><font color=#38B2AC>Chen, X.</font></strong>, Chen, W., Cai, R., <strong>2023</strong>. A Survey on Causal Discovery with Incomplete Time-Series Data. <font color=#FF5733>In <em>Xuanzhi’s Personal Website.</font></em> [<a href="papers/a_survey_on_causal_discovery_with_incomplete_time-series_data.pdf">paper</a>] [<a href="slides/a_survey_on_causal_discovery_with_incomplete_time-series_data.pdf">slides</a>]</li>
</ul>
<!-- ### 2023 -->
<ul>
<li>
<p><strong><font color=#38B2AC>Chen, X.*</font></strong>, Chen, W.*, Cai, R., <strong>2023</strong>. Non-linear Causal Discovery for Additive Noise Model with Multiple Latent Confounders.
<font color=#FF5733>In <em>Xuanzhi’s Personal Website.</font></em>
[<a href="papers/nonlinear_mlc.pdf">paper</a>] [<a href="slides/nonlinear_mlc.pdf">slides</a>] [<a href="https://www.youtube.com/watch?v=4bpx1DPd_Vg&amp;list=PLSyPZ5M_YtDRr9z25YgUjqs7-RLr-x5yg&amp;index=2">talk</a>] [<a href="https://github.com/xuanzhichen/cadimulc/blob/master/cadimulc/hybrid_algorithms/hybrid_algorithms.py">code</a>]</p>
  <!-- > This unpublished paper is a complete work that should have been scheduled for submission, but collaboration among authors came to an early cessation, due to Xuanzhi's personal inconvenience. -->
</li>
<li>
<p><strong><font color=#38B2AC>Chen, X.</font></strong>, <strong>2023</strong>. Supplementary Material to: &ldquo;Non-linear Causal Discovery for Additive Noise Model with Multiple Latent Confounders&rdquo;. <font color=#FF5733>In <em>Xuanzhi’s Personal Website.</font></em> [<a href="papers/nonlinear_mlc_supplementary_material.pdf">paper</a>]</p>
</li>
</ul>
<h3 id="personal-essaies">Personal Essaies</h3>
<ul>
<li><strong><font color=#38B2AC>Chen, X.</font></strong>, <strong>2024</strong>. A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective.
<font color=#FF5733>In <em>Xuanzhi’s Personal Website.</font></em>
[<a href="papers/primer_causal_diagram_learning.pdf">paper</a>] [<a href="slides/primer_causal_diagram_learning.pdf">slides</a>] [<a href="https://www.youtube.com/playlist?list=PLSyPZ5M_YtDQA6YQ7VNGVoNlYZYo_xgpu">talk</a>]
  <!-- > This unpublished paper serves as an open resource focusing on popularization of causal science, sharing Xuanzhi's personal opinions based on his research experience in causal discovery. --></li>
</ul>

</article>


      

      



      

      
      



    </div>
    
      <div class="col-span-2">
        
        
          <div
  class="
    bg-secondary-bg
   prose sticky top-16 z-10 hidden px-8 py-4 lg:block"
>
  <h3>On This Page</h3>
</div>
<div
  class="sticky-toc  hidden px-6 pb-6 lg:block"
>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#popularization-of-causal-science-2023-2024">Popularization of Causal Science (2023-2024)</a></li>
    <li><a href="#causality-algorithms-programming-2022-2023">Causality Algorithms Programming (2022-2023)</a></li>
    <li><a href="#research-in-causal-science-2-2023">Research in Causal Science (2) (2023)</a></li>
    <li><a href="#research-in-causal-science-1-2022-2023">Research in Causal Science (1) (2022-2023)</a></li>
    <li><a href="#academic-papers">Academic Papers</a>
      <ul>
        <li><a href="#publishments">Publishments</a></li>
        <li><a href="#preprints">Preprints</a></li>
        <li><a href="#personal-essaies">Personal Essaies</a></li>
      </ul>
    </li>
  </ul>
</nav>
</div>
<script>
  window.addEventListener("DOMContentLoaded", () => {
    enableStickyToc();
  });
</script>

        
      </div>
    

    
    
  </div>

  
    <script>
      document.addEventListener("DOMContentLoaded", () => {
        hljs.highlightAll();
      });
    </script>

          </div>
        </div>
      
    </main>
    
  </body>
</html>
