<!DOCTYPE html>
<html
  lang="en"
  dir="ltr"
  
><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">


<title>Work | Homepage</title>

<meta name="generator" content="Hugo Eureka 0.9.3" />
<link rel="stylesheet" href="https://xuanzhichen.github.io/css/eureka.min.9cec6350e37e534b0338fa9a085bf06855de3b0f2dcf857e792e5e97b07ea905d4d5513db554cbc26a9c3da622bae92d.css">
<script defer src="https://xuanzhichen.github.io/js/eureka.min.fa9a6bf6d7a50bb635b4cca7d2ba5cf3dfb095ae3798773f1328f7950028b48c17d06276594e1b5f244a25a6c969a705.js"></script>













<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
  href="https://fonts.googleapis.com/css2?family=Lora:wght@400;600;700&amp;family=Noto&#43;Serif&#43;SC:wght@400;600;700&amp;display=swap"
  as="style" onload="this.onload=null;this.rel='stylesheet'">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/styles/base16/solarized-light.min.css"
   media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/highlight.min.js"
   crossorigin></script>
  <script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/languages/dart.min.js"
     crossorigin></script>
<link rel="stylesheet" href="https://xuanzhichen.github.io/css/highlightjs.min.2958991528e43eb6fc9b8c4f2b8e052f79c4010718e1d1e888a777620e9ee63021c2c57ec7417a3108019bb8c41943e6.css" media="print" onload="this.media='all';this.onload=null">


<script defer type="text/javascript" src="https://xuanzhichen.github.io/js/fontawesome.min.95304b4ae74be494ff20fcc4a2da53d579715352f453ee025f7b41e1ab63b5b52a82c7e2403d9e3742b73d2fbd69b5be.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"
   integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ"  media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" 
  integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY"  crossorigin></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
   integrity="sha384-&#43;XBljXPPiv&#43;OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"  crossorigin></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
        { left: "\\(", right: "\\)", display: false },
        { left: "\\[", right: "\\]", display: true }
      ],
    });
  });
</script>


<script defer src="https://cdn.jsdelivr.net/npm/mermaid@8.14.0/dist/mermaid.min.js" 
  integrity="sha384-atOyb0FxAgN9LyAc6PEf9BjgwLISyansgdH8/VXQH8p2o5vfrRgmGIJ2Sg22L0A0"  crossorigin></script>
<link rel="preconnect" href="https://www.google-analytics.com" crossorigin>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123-45"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());
  gtag('config', 'UA-123-45');
</script>



<meta name="description"
  content="Projects Introduction Aug. 2023 – Mar. 2024 A Primer on Causal Diagram Learning (Work for Popularization of Science and Technology)
For details, also see the article &lsquo;A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective&rsquo; in Papers.2024 on this page.
Since I was motivated by fundamental ideas of causality from a popular science book named &lsquo;The Book of WHY&rsquo;, I attempt to further create connections in the book to other celebrated books by leaders in causation, centering around subjects of &ldquo;causal diagram learning&rdquo;.">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
      "@type": "ListItem",
      "position": 1 ,
      "name":"Homepage",
      "item":"https://xuanzhichen.github.io/"},{
      "@type": "ListItem",
      "position": 2 ,
      "name":"Work",
      "item":"https://xuanzhichen.github.io/work/"}]
}
</script>



<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://xuanzhichen.github.io/work/"
    },
    "headline": "Work | Homepage","wordCount":  477 ,
    "publisher": {
        "@type": "Person",
        "name": "Homepage",
        },
    "description": "Projects Introduction Aug. 2023 – Mar. 2024 A Primer on Causal Diagram Learning (Work for Popularization of Science and Technology)\nFor details, also see the article \u0026lsquo;A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective\u0026rsquo; in Papers.2024 on this page.\nSince I was motivated by fundamental ideas of causality from a popular science book named \u0026lsquo;The Book of WHY\u0026rsquo;, I attempt to further create connections in the book to other celebrated books by leaders in causation, centering around subjects of \u0026ldquo;causal diagram learning\u0026rdquo;."
}
</script><meta property="og:title" content="Work | Homepage" />
<meta property="og:type" content="article" />



<meta property="og:url" content="https://xuanzhichen.github.io/work/" />




<meta property="og:description" content="Projects Introduction Aug. 2023 – Mar. 2024 A Primer on Causal Diagram Learning (Work for Popularization of Science and Technology)
For details, also see the article &lsquo;A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective&rsquo; in Papers.2024 on this page.
Since I was motivated by fundamental ideas of causality from a popular science book named &lsquo;The Book of WHY&rsquo;, I attempt to further create connections in the book to other celebrated books by leaders in causation, centering around subjects of &ldquo;causal diagram learning&rdquo;." />




<meta property="og:locale" content="en" />



<meta property="og:locale:alternate" content="zh" />




<meta property="og:site_name" content="Homepage" />









<meta property="article:section" content="" />





  
  <body class="bg-secondary-bg flex min-h-screen flex-col">
    <header
      class="min-h-16 pl-scrollbar bg-secondary-bg fixed z-50 flex w-full items-center shadow-sm"
    >
      <div class="mx-auto w-full max-w-screen-xl"><script>
    let storageColorScheme = localStorage.getItem("lightDarkMode")
    if (((storageColorScheme == 'Auto' || storageColorScheme == null) && window.matchMedia("(prefers-color-scheme: dark)").matches) || storageColorScheme == "Dark") {
        document.getElementsByTagName('html')[0].classList.add('dark')
    }
</script>
<nav class="flex items-center justify-between flex-wrap px-4 py-4 md:py-0">
    <a href="/" class="me-6 text-primary-text text-xl font-bold">Homepage</a>
    <button id="navbar-btn" class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
        <i class="fas fa-bars"></i>
    </button>

    <div id="target"
        class="hidden block md:flex md:grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20">
        <div class="md:flex md:h-16 text-sm md:grow pb-4 md:pb-0 border-b md:border-b-0">
            <a href="/cv/cv2.pdf" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">CV</a>
            <a href="/experience/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">Experience &amp; News</a>
            <a href="/work/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  selected-menu-item  me-4">Work</a>
            <a href="/acknowledgements/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">Acknowledgements</a>
            <a href="/blogs/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">Blogs</a>
        </div>

        <div class="flex">
            <div class="relative pt-4 md:pt-0">
                <div class="cursor-pointer hover:text-eureka" id="lightDarkMode">
                    <i class="fas fa-adjust"></i>
                </div>
                <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id="is-open">
                </div>
                <div class="absolute flex flex-col start-0 md:start-auto end-auto md:end-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40"
                    id='lightDarkOptions'>
                    <span class="px-4 py-1 hover:text-eureka" name="Light">Light</span>
                    <span class="px-4 py-1 hover:text-eureka" name="Dark">Dark</span>
                    <span class="px-4 py-1 hover:text-eureka" name="Auto">Auto</span>
                </div>
            </div>
            <div class="relative pt-4 ps-4 md:pt-0">
                <div class="cursor-pointer hover:text-eureka" id="languageMode">
                    <i class="fas fa-globe"></i>
                    <span class="ps-1">English</span>
                </div>
                <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id="is-open-lang">
                </div>
                <div class="absolute flex flex-col start-0 md:start-auto end-auto md:end-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40"
                    id='languageOptions'>
                    <a class="px-4 py-1 hover:text-eureka" href="https://xuanzhichen.github.io/work/">English</a>
                    <a class="px-4 py-1 hover:text-eureka" href="https://xuanzhichen.github.io/zh/work/">简体中文</a>
                </div>
            </div>
        </div>
    </div>

    <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id="is-open-mobile">
    </div>

</nav>
<script>
    
    let element = document.getElementById('lightDarkMode')
    if (storageColorScheme == null || storageColorScheme == 'Auto') {
        document.addEventListener('DOMContentLoaded', () => {
            window.matchMedia("(prefers-color-scheme: dark)").addEventListener('change', switchDarkMode)
        })
    } else if (storageColorScheme == "Light") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'sun')
        element.firstElementChild.classList.add('fa-sun')
    } else if (storageColorScheme == "Dark") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'moon')
        element.firstElementChild.classList.add('fa-moon')
    }

    document.addEventListener('DOMContentLoaded', () => {
        getcolorscheme();
        switchBurger();
        switchLanguage()
    });
</script>
</div>
    </header>
    <main class="grow pt-16">
        <div class="pl-sc rollbar">
          <div class="mx-auto w-full max-w-screen-xl lg:px-4 xl:px-8">
  
  

  
  <div class="grid grid-cols-2 gap-4 lg:grid-cols-8 lg:pt-16">
    <div
      class=" bg-secondary-bg col-span-2 rounded px-6 py-8 lg:col-span-6"
    >
      <article class="prose">
  <h1 class="mb-4">Work</h1>

  

  
  

  <h2 id="projects-introduction">Projects Introduction</h2>
<h3 id="aug-2023--mar-2024">Aug. 2023 – Mar. 2024</h3>
<p><strong><a href="https://www.youtube.com/playlist?list=PLSyPZ5M_YtDQA6YQ7VNGVoNlYZYo_xgpu">A Primer on Causal Diagram Learning</a></strong>
<strong><font color=#38B2AC>(<em>Work for Popularization of Science and Technology</em>)</font></strong></p>
<blockquote>
<p>For details, also see the article &lsquo;<em>A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective</em>&rsquo; in <code>Papers.2024</code> on this page.</p>
</blockquote>
<!-- - Notions of <font color=#38B2AC>counterfactuals</font> and <font color=#38B2AC>intervention</font>, the paradigm of human causal thinking, are introduced into two (simplified) applications
of causal relation analysis in significant issues such as <font color=#38B2AC>climate
change</font> and <font color=#38B2AC>COVID-19</font>.

- Introduce the <font color=#38B2AC>"down-stream" capability</font> of a given causal diagram, and retrospectively the <font color=#38B2AC>"upstream" task</font>
focusing on how to learn the causal diagram—namely the "Causal Discovery". -->
<ul>
<li>Since I was motivated by fundamental ideas of causality from a popular science book named &lsquo;<a href="https://en.wikipedia.org/wiki/The_Book_of_Why">The Book of WHY</a>&rsquo;, I attempt to further create <font color=#38B2AC>connections</font> in the book to other <font color=#38B2AC>celebrated books by leaders in causation</font>, centering around subjects of &ldquo;<font color=#38B2AC>causal diagram learning</font>&rdquo;.</li>
<li>I want to show that ideas of Causal Discovery are deeply rooted in the past by <font color=#38B2AC>standing on the shoulders of these giants</font>. Of course,
ideas of causal diagram learning introduced in this paper are the tip of the iceberg. However, I wish that points of view from the work of the giants in causal science <font color=#38B2AC>might be beneficial to future progression of AI, cognitive neuroscience, and other related fields</font>.</li>
</ul>
<!-- three of celebrated books herein include: Causation, Prediction, and Search [2001] (Peter Spirtes, Clark Glymour); Causality [2008] (Judea Pearl); Elements of Causal Inference [2017] (Jonas Peters, Bernhard Schölkopf, etc).  -->
<!-- - Also see the article "*A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective*" in `Papers.2024` on this page. -->
<h3 id="may-2022----jun-2023">May. 2022 &ndash; Jun. 2023</h3>
<p><strong><a href="https://xuanzhichen.github.io/cadimulc/">Cadimulc: Light Python Package for Hybrid-Based Causal Discovery</a></strong>
<strong><font color=#38B2AC>(<em>Software</em>)</font></strong></p>
<ul>
<li>
<p><font color=#38B2AC>CADIMULC</font> is a <a href="https://github.com/xuanzhichen/cadimulc">Python package</a> standing for <font color=#38B2AC>CA</font>usal <font color=#38B2AC>DI</font>scovery with <font color=#38B2AC>M</font>ultiple <font color=#38B2AC>L</font>atent <font color=#38B2AC>C</font>onfounders.</p>
</li>
<li>
<p>The package provides easy-to-use light APIs to learn an empirical causal graph from generally raw data with relatively efficiency. For example, It integrates the implementations of <font color=#38B2AC>hybrid-based causal discovery approaches</font> such as the <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=Causal+discovery+in+linear+non-gaussian+acyclic+model+with+multiple+latent+confounders&amp;btnG=">MLC-LiNGAM algorithm</a>,
along with the &ldquo;micro&rdquo; <font color=#38B2AC>workflow of causal discovery</font>, such as data generation, learning results evaluation, and graphs visualization.</p>
</li>
</ul>
<h3 id="nov-2021--jun-2023">Nov. 2021 – Jun. 2023</h3>
<p><strong><a href="https://www.youtube.com/playlist?list=PLSyPZ5M_YtDRr9z25YgUjqs7-RLr-x5yg">Nonlinear Causal Discovery from Unknown Confounding</a></strong>
<strong><font color=#38B2AC>(<em>Scientific Research</em>)</font></strong></p>
<blockquote>
<p>For details, also see the article &lsquo;<em>Non-linear Causal Discovery for Additive Noise Model with Multiple Latent Confounders</em>&rsquo; in <code>Papers.2023</code> on this page.</p>
</blockquote>
<ul>
<li>Could we teach AI in brain science spectrum to manoeuvre causation via the <font color=#38B2AC>specific identification</font> entailed by data? How should we further appreciate “<font color=#38B2AC>causal structures</font>” underneath the data in a <font color=#38B2AC>complicate learning environment</font>? An environment in which
&ldquo;generic data relations&rdquo; are prone to be <font color=#38B2AC>non-linear</font>, and even impacts from the <font color=#38B2AC>multiple
unknown factors</font> are persisting.</li>
<li>Existing solutions towards the issue might be either <font color=#38B2AC>theoretically elusive in formal representation</font> or <font color=#38B2AC>notoriously difficult in algorithmic computation</font>. Such motivations have driven us to a <font color=#38B2AC>theory-guided</font> and <font color=#38B2AC>effective</font> causal discovery algorithm.</li>
</ul>
<!-- - Causal discovery, namely to recover <font color=#38B2AC>data generation</font> mechanism represented (vaguely) by <font color=#38B2AC>causal graphs</font>,
is an emerging scientific discipline to spot causal significance from the merely observed and static data.

- Practically, only <font color=#38B2AC>a subset of</font> variables relative to the reasonable dataset has been measured, leading to
<font color=#38B2AC>potential confounding</font> from these latent variables; meanwhile, <font color=#38B2AC>causality constraints</font> that have paid off
in linear cases are now impeded, due to the <font color=#38B2AC>general non-linear</font> interaction between variables. -->
<h2 id="papers">Papers</h2>
<!-- ### Working
- **<font color=#38B2AC>*Chen, XZ.*</font>** A Brief Discussion on Causal Inference for Time-Series Data -->
<h3 id="2024">2024</h3>
<ul>
<li><strong><font color=#38B2AC>Chen, XZ.</font></strong>, 2024. A Primer on Causal Diagram Learning: Interpreting Causation from the Causal Discovery Perspective
<font color=#FF5733>In <em>Xuanzhi’s Personal Website.</font></em>
[<a href="papers/primer_causal_diagram_learning.pdf">pdf</a>] [<a href="https://www.youtube.com/playlist?list=PLSyPZ5M_YtDQA6YQ7VNGVoNlYZYo_xgpu">video</a>]</li>
</ul>
<!-- 
    > Since I was motivated by fundamental ideas of causality from
    a popular science book named 'The Book of WHY', I attempt to
    further create connections in the book to other celebrated books
    by leaders in causation. Centering around subjects of "causal
    diagram learning", three of celebrated books herein include:
    Causation, Prediction, and Search [2001] (Peter Spirtes, Clark
    Glymour); Causality [2008] (Judea Pearl); Elements of Causal
    Inference [2017] (Jonas Peters, Bernhard Schölkopf, etc). Hence,
    I want to show that ideas of Causal Discovery are deeply rooted
    in the past by standing on the shoulders of these giants.

    > Ideas of causal diagram learning introduced in this
    paper are the tip of the iceberg. However, I hope that points
    of view from the work of the giants in causal science might be
    beneficial to future progression of AI, cognitive neuroscience,
    and other related fields. -->
<h3 id="2023">2023</h3>
<ul>
<li><strong><font color=#38B2AC>Chen, XZ.</font></strong>, Chen, W., Cai, RC., 2023. Non-linear Causal Discovery for Additive Noise Model with Multiple Latent Confounders.
<font color=#FF5733>In <em>Xuanzhi’s Personal Website.</font></em>
[<a href="papers/nonlinear_mlc.pdf">pdf</a>] [<a href="https://github.com/xuanzhichen/cadimulc/blob/master/cadimulc/hybrid_algorithms/hybrid_algorithms.py">code</a>] [<a href="https://www.youtube.com/playlist?list=PLSyPZ5M_YtDRr9z25YgUjqs7-RLr-x5yg">video</a>]</li>
</ul>
<!-- 
    > We re-analyzed the celebrated non-linear Additive Noise Models and discovered a novel identification that gives rise to a  well-performance causal discovery algorithm on functional magnetic resonance imaging (fMRI) brain data. -->
<ul>
<li>Chen, XZ., 2023. Supplementary Material to: &ldquo;Non-linear Causal Discovery for Additive Noise Model with Multiple Latent Confounders.&rdquo;
In <em>Xuanzhi’s Personal Website.</em>
[<a href="papers/nonlinear_mlc_supplementary_material.pdf">pdf</a>]</li>
</ul>
<h3 id="2022">2022</h3>
<!-- - *Liu, YQ.\*, Zhu, WH.\*, Qiao, J.\*, Huang, ZY., Xiang, Yu.,* **<font color=#38B2AC>*Chen, XZ.*</font>**, *Chen, W., Cai, RC.* **[Causal Alignment Based Fault Root Causes Localization for Wireless Network](https://ieeexplore.ieee.org/abstract/document/9746064)**.
*<font color=#FF5733>ICASSP; IEEE International Conference on Acoustics, Speech and Signal Processing.</font>* -->
<ul>
<li>Liu, Y., Zhu, W., Qiao, J., Huang, Z., Xiang, Y., <strong><font color=#38B2AC>Chen, XZ.</font></strong>, Chen, W. and Cai, R., 2022, May. <a href="https://ieeexplore.ieee.org/abstract/document/9746064">Causal Alignment Based Fault Root Causes Localization for Wireless Network</a>. <font color=#FF5733>In <em>ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> (pp. 9311-9315). IEEE.</font>
  <!-- > Though supervised methods have shown promising results, most of the existing approaches assume that
  the training and the testing samples are independent and
  identical distributed. Such an assumption usually does
  not hold due to network faults that may occur across different domains (distribution shift). Thus, it is necessary to align distributions between
  the training and test data set.  --></li>
</ul>

</article>


      

      



      

      
      



    </div>
    
      <div class="col-span-2">
        
        
          <div
  class="
    bg-secondary-bg
   prose sticky top-16 z-10 hidden px-8 py-4 lg:block"
>
  <h3>On This Page</h3>
</div>
<div
  class="sticky-toc  hidden px-6 pb-6 lg:block"
>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#projects-introduction">Projects Introduction</a>
      <ul>
        <li><a href="#aug-2023--mar-2024">Aug. 2023 – Mar. 2024</a></li>
        <li><a href="#may-2022----jun-2023">May. 2022 &ndash; Jun. 2023</a></li>
        <li><a href="#nov-2021--jun-2023">Nov. 2021 – Jun. 2023</a></li>
      </ul>
    </li>
    <li><a href="#papers">Papers</a>
      <ul>
        <li><a href="#2024">2024</a></li>
        <li><a href="#2023">2023</a></li>
        <li><a href="#2022">2022</a></li>
      </ul>
    </li>
  </ul>
</nav>
</div>
<script>
  window.addEventListener("DOMContentLoaded", () => {
    enableStickyToc();
  });
</script>

        
      </div>
    

    
    
  </div>

  
    <script>
      document.addEventListener("DOMContentLoaded", () => {
        hljs.highlightAll();
      });
    </script>

          </div>
        </div>
      
    </main>
    
  </body>
</html>
